{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcA-wg7C-bAk",
        "outputId": "8fbbf174-58b2-4a92-87ec-6f61021095e1"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from numpy.linalg import inv\r\n",
        "import csv\r\n",
        "import math\r\n",
        "from numpy import linalg \r\n",
        "import random\r\n",
        "from google.colab import drive\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "drive.mount('/content/drive')\r\n",
        "filenameArr = []\r\n",
        "labelArr_long = []\r\n",
        "labelArr = []\r\n",
        "\r\n",
        "filenameArrYY = []\r\n",
        "labelArr_longYY = []\r\n",
        "labelArrYY = []\r\n",
        "\r\n",
        "trainRoot = \"drive/MyDrive/Colab Notebooks/Trail_dataset/Trail_dataset/train_data/\"  \r\n",
        "testRoot = \"drive/MyDrive/Colab Notebooks/Trail_dataset/Trail_dataset/test_data/\" \r\n",
        "\r\n",
        "for path, subdirs, files in os.walk(trainRoot):\r\n",
        "  for name in files:\r\n",
        "    if ((len(name) > 5)and(name[len(name)-1] == 'g')):\r\n",
        "      labelArr.append(float(name.split('_')[0]))\r\n",
        "      labelArr_long.append(float((name.split('.')[0] + '.' + name.split('.')[1]).replace('_', '')))\r\n",
        "      filenameArr.append(os.path.join(path,name))\r\n",
        "print(len(filenameArr))\r\n",
        "\r\n",
        "for path, subdirs, files in os.walk(testRoot):\r\n",
        "  for name in files:\r\n",
        "    if ((len(name) > 5)and(name[len(name)-1] == 'g')):\r\n",
        "      labelArr_longYY.append(float(name.split('_')[0]))\r\n",
        "      labelArr_longYY.append(float((name.split('.')[0] + '.' + name.split('.')[1]).replace('_', '')))\r\n",
        "      filenameArrYY.append(os.path.join(path,name))\r\n",
        "print(len(filenameArrYY))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "5717\n",
            "852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3B6wFd6AxIm"
      },
      "source": [
        "class CNN_Model(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(CNN_Model, self).__init__()\r\n",
        "    self.conv1 = nn.Conv2d(3, 16, 5)\r\n",
        "    self.conv2 = nn.Conv2d(16, 32, 5)\r\n",
        "    self.conv3 = nn.Conv2d(32, 64, 5)\r\n",
        "    self.maxpooll = nn.MaxPool2d(kernel_size=2) \r\n",
        "    self.fc1 = nn.Linear(2179072, 100)\r\n",
        "    self.layer = torch.nn.Linear(100, 1)\r\n",
        "    self.dropout = nn.Dropout(0.5)\r\n",
        "  def forward(self, x):\r\n",
        "    x = F.relu(self.conv1(x))\r\n",
        "    x = self.maxpooll(x)\r\n",
        "    x = self.dropout(x)\r\n",
        "    x = F.relu(self.conv2(x))\r\n",
        "    x = self.maxpooll(x)\r\n",
        "    x = self.dropout(x)\r\n",
        "    x = F.relu(self.conv3(x))\r\n",
        "    x = self.maxpooll(x)\r\n",
        "    x = x.view(-1, 2179072)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = self.dropout(x)\r\n",
        "    x = self.layer(x)  \r\n",
        "    return x\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyGfBU0R6coe"
      },
      "source": [
        "# 新增區段"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgKIoNBUBKSs"
      },
      "source": [
        "LR = 0.01\r\n",
        "batch_size = 8\r\n",
        "n_iters = 50\r\n",
        "nowX = 128\r\n",
        "nowY = 128\r\n",
        "num_epochs = n_iters / ((nowX) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        "\r\n",
        "model = CNN_Model()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\r\n",
        "loss_func = nn.MSELoss(reduction=\"none\")   \r\n",
        "input_shape = (-1,3,480,640)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVI1Yp7IBOas"
      },
      "source": [
        "def fit_model(model, loss_func, optimizer, input_shape, num_epochs, train_loader, test_loader):\r\n",
        "    training_loss = []\r\n",
        "    validation_loss = []\r\n",
        "    a = 0\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        a += 1\r\n",
        "        print(\"a: \",a)\r\n",
        "        for i, (images, labels) in enumerate(train_loader):\r\n",
        "            \r\n",
        "            train = Variable(images.view(input_shape))\r\n",
        "            labels = Variable(labels)\r\n",
        "            optimizer.zero_grad()\r\n",
        "            outputs = model(train)\r\n",
        "            train_loss = loss_func(outputs, labels)\r\n",
        "            \r\n",
        "            train_loss.backward(torch.ones(1,batch_size))\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "        training_loss.append(train_loss.data)\r\n",
        "\r\n",
        "        for images, labels in test_loader:\r\n",
        "            test = Variable(images.view(input_shape))\r\n",
        "            outputs = model(test)\r\n",
        "            val_loss = loss_func(outputs, labels)\r\n",
        "\r\n",
        "        validation_loss.append(val_loss.data)\r\n",
        "        print('Train Epoch: {}/{} Traing_Loss: {}  Val_Loss: {} '.format(epoch+1, num_epochs, train_loss.data, val_loss.data))\r\n",
        "    return training_loss, validation_loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2awGuBasBbL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ec6912-c35f-486d-e718-1c30471e63c7"
      },
      "source": [
        "# c1 = list(zip(filenameArr, labelArr_long, labelArr))\r\n",
        "# random.shuffle(c1) \r\n",
        "# filenameArr, labelArr_long, labelArr = zip(*c1)\r\n",
        "\r\n",
        "X_train = []\r\n",
        "Y_train = []\r\n",
        "X_test = []\r\n",
        "Y_test = []\r\n",
        "\r\n",
        "for u in range(nowX):\r\n",
        "    this_image = mpimg.imread(filenameArr[u])\r\n",
        "    this_image = np.array(this_image)\r\n",
        "    this_image = this_image.astype('float32')\r\n",
        "    this_image = np.transpose(this_image, (2, 0, 1))\r\n",
        "    X_train.append(this_image)\r\n",
        "    Y_train.append(labelArr_long[u])\r\n",
        "X_train = torch.from_numpy(np.array(X_train)).float()\r\n",
        "Y_train = torch.from_numpy(np.array(Y_train)).float()\r\n",
        "print(X_train.shape)\r\n",
        "print(Y_train.shape)\r\n",
        "\r\n",
        "for u in range(nowY):\r\n",
        "    this_image = mpimg.imread(filenameArrYY[u])\r\n",
        "    this_image = np.array(this_image)\r\n",
        "    this_image = this_image.astype('float32')\r\n",
        "    this_image = np.transpose(this_image, (2, 0, 1))\r\n",
        "    X_test.append(this_image)\r\n",
        "    Y_test.append(labelArr_longYY[u])\r\n",
        "X_test = torch.from_numpy(np.array(X_test)).float()\r\n",
        "Y_test = torch.from_numpy(np.array(Y_test)).float()\r\n",
        "print(X_test.shape)\r\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 480, 640])\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVX9ihgNBcd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08512bed-9577-43fc-adea-88a41dd9a8e9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "train = torch.utils.data.TensorDataset(X_train,Y_train)\r\n",
        "test = torch.utils.data.TensorDataset(X_test,Y_test)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\r\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)\r\n",
        "\r\n",
        "training_loss, validation_loss = fit_model(model, loss_func, optimizer, input_shape, num_epochs, train_loader, test_loader)\r\n",
        "#print(training_loss)\r\n",
        "#print(validation_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1/3 Traing_Loss: tensor([[7.2029e-04, 7.2029e-04, 5.3286e-04, 1.7485e-03, 1.3559e-03, 6.6866e-03,\n",
            "         3.5241e-06, 4.4590e-03]])  Val_Loss: tensor([[0.1569, 0.1453, 0.1130, 0.1233, 0.1901, 0.1773, 0.1945, 0.1415]]) \n",
            "a:  2\n",
            "Train Epoch: 2/3 Traing_Loss: tensor([[1.1499e-03, 4.7410e-03, 5.7243e-04, 6.7682e-04, 8.0082e-05, 3.6333e-05,\n",
            "         5.7242e-04, 2.9029e-03]])  Val_Loss: tensor([[0.1630, 0.2243, 0.2013, 0.1397, 0.1712, 0.2013, 0.1360, 0.1511]]) \n",
            "a:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI9_ioMBBd1U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}